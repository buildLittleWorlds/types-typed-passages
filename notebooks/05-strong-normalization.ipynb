{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Strong Normalization\n",
    "\n",
    "*Every Typed Term Terminates*\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/buildLittleWorlds/types-typed-passages/blob/main/notebooks/05-strong-normalization.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## A Note from the Archives\n",
    "\n",
    "> *Year 830, Capital Archives*\n",
    ">\n",
    "> Brennis Mund had done it. After thirty years of work, he had proven the theorem that would ensure the Archive's safety forever.\n",
    ">\n",
    "> **Strong Normalization**: Every well-typed term terminates.\n",
    ">\n",
    "> No more seven-hour halts. No more Omega variants slipping through review. If a passage passed the typing discipline, it was guaranteed to reduce to a normal form.\n",
    ">\n",
    "> His father Kelleth had seen the problem. Brennis had found the solution.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this tutorial, you will be able to:\n",
    "\n",
    "1. State the Strong Normalization theorem\n",
    "2. Distinguish between weak and strong normalization\n",
    "3. Understand why types guarantee termination\n",
    "4. Recognize that this solves the Omega problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://raw.githubusercontent.com/buildLittleWorlds/densworld-datasets/main/data/\"\n",
    "\n",
    "expressions_df = pd.read_csv(BASE_URL + \"typed_passage_expressions.csv\")\n",
    "traces_df = pd.read_csv(BASE_URL + \"normalization_traces.csv\")\n",
    "\n",
    "print(f\"Loaded {len(expressions_df)} expressions\")\n",
    "print(f\"Loaded {len(traces_df)} reduction steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Normalization?\n",
    "\n",
    "An expression **normalizes** if it eventually reduces to a normal form (a value that cannot reduce further).\n",
    "\n",
    "**Weak normalization**: There *exists* a reduction sequence that terminates\n",
    "\n",
    "**Strong normalization**: *Every* reduction sequence terminates\n",
    "\n",
    "The difference matters because lambda calculus allows choice of which redex to reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak vs Strong normalization\n",
    "print(\"Normalization Concepts:\")\n",
    "print()\n",
    "print(\"  WEAK: At least one path to normal form\")\n",
    "print(\"  Example: (λx.y) Ω\")\n",
    "print(\"    - Reduce (λx.y) Ω → y  ✓ (ignoring Ω)\")\n",
    "print(\"    - Reduce Ω first → loops forever ✗\")\n",
    "print(\"  Weakly normalizing (one good path exists)\")\n",
    "print()\n",
    "print(\"  STRONG: ALL paths lead to normal form\")\n",
    "print(\"  Example: (λx.x)(λy.y)\")\n",
    "print(\"    - Only one redex, reduces to λy.y ✓\")\n",
    "print(\"  Strongly normalizing (no bad paths exist)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Strong Normalization Theorem\n",
    "\n",
    "**Theorem (Strong Normalization for STLC)**:\n",
    "\n",
    "> If $\\Gamma \\vdash M : \\tau$, then every reduction sequence starting from $M$ is finite.\n",
    "\n",
    "In words: **Every well-typed term terminates, no matter how you reduce it.**\n",
    "\n",
    "This is the ultimate answer to the Omega problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All typed expressions terminate\n",
    "typed_exprs = expressions_df[expressions_df['typable'] == True]\n",
    "\n",
    "print(\"Typed expressions and termination:\")\n",
    "print()\n",
    "\n",
    "terminates_count = typed_exprs['terminates'].sum()\n",
    "total_typed = len(typed_exprs)\n",
    "\n",
    "print(f\"  Typed expressions: {total_typed}\")\n",
    "print(f\"  Terminate: {terminates_count}\")\n",
    "print(f\"  Percentage: {100*terminates_count/total_typed:.0f}%\")\n",
    "print()\n",
    "print(\"  Strong Normalization guarantees 100% termination!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Why Types Guarantee Termination\n",
    "\n",
    "The key insight: every reduction **decreases** some measure.\n",
    "\n",
    "For simply typed lambda calculus, we can use the **size of the type** as a measure:\n",
    "\n",
    "- Base types have size 1\n",
    "- Arrow types: $|\\tau_1 \\to \\tau_2| = |\\tau_1| + |\\tau_2| + 1$\n",
    "\n",
    "When we reduce $(\\lambda x.M)\\ N$, the substitution $M[N/x]$ has a \"smaller\" type structure (in a precise sense)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intuition for why types help\n",
    "print(\"Why Types Guarantee Termination (Intuition):\")\n",
    "print()\n",
    "print(\"  The type of a redex (λx:τ₁.M):τ₁→τ₂ applied to N:τ₁\")\n",
    "print(\"  is τ₂.\")\n",
    "print()\n",
    "print(\"  After reduction, M[N/x] has type τ₂.\")\n",
    "print()\n",
    "print(\"  The 'complexity' of the typing derivation decreases.\")\n",
    "print(\"  Since it can't decrease forever, reduction terminates.\")\n",
    "print()\n",
    "print(\"  (The formal proof uses 'reducibility candidates'.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Observing Termination in Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show reduction lengths for various expressions\n",
    "print(\"Reduction lengths for typed expressions:\")\n",
    "print()\n",
    "\n",
    "for trace_id in traces_df['trace_id'].unique():\n",
    "    trace = traces_df[traces_df['trace_id'] == trace_id]\n",
    "    expr = trace.iloc[0]['expression']\n",
    "    type_ = trace.iloc[0]['type']\n",
    "    steps = len(trace) - 1  # Subtract 1 because we count transitions\n",
    "    final = trace[trace['is_value'] == True]\n",
    "    \n",
    "    if len(final) > 0:\n",
    "        final_term = final.iloc[0]['current_term']\n",
    "        if len(final_term) > 20:\n",
    "            final_term = final_term[:17] + \"...\"\n",
    "        print(f\"  {trace_id}: {steps} steps → {final_term}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The SUCC Chain Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace SUCC ZERO\n",
    "trace_succ = traces_df[traces_df['trace_id'] == 'NT-004']\n",
    "\n",
    "print(\"SUCC ZERO reduction:\")\n",
    "print(f\"Type: {trace_succ.iloc[0]['type']}\")\n",
    "print()\n",
    "\n",
    "for _, row in trace_succ.iterrows():\n",
    "    term = row['current_term']\n",
    "    if len(term) > 50:\n",
    "        term = term[:47] + \"...\"\n",
    "    marker = \" [VALUE]\" if row['is_value'] else \"\"\n",
    "    print(f\"  Step {row['step_number']}: {term}{marker}\")\n",
    "\n",
    "print()\n",
    "print(\"  SUCC ZERO = ONE. Terminates in finite steps!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Contrast: Omega Does NOT Normalize\n",
    "\n",
    "Omega reduces to itself forever:\n",
    "\n",
    "$$\\Omega = (\\lambda x.x\\ x)(\\lambda x.x\\ x) \\to \\Omega \\to \\Omega \\to \\ldots$$\n",
    "\n",
    "But Omega is **untypable**! Strong Normalization only applies to well-typed terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Omega doesn't normalize\n",
    "omega = expressions_df[expressions_df['expression'].str.contains('\\(λx\\.x x\\)\\(λx\\.x x\\)', na=False, regex=True)]\n",
    "\n",
    "if omega.empty:\n",
    "    # Try simpler pattern\n",
    "    omega = expressions_df[expressions_df['expression_id'] == 'TPE-009']\n",
    "\n",
    "print(\"Omega and termination:\")\n",
    "print()\n",
    "if not omega.empty:\n",
    "    row = omega.iloc[0]\n",
    "    print(f\"  Expression: {row['expression']}\")\n",
    "    print(f\"  Typable: {row['typable']}\")\n",
    "    print(f\"  Terminates: {row['terminates']}\")\n",
    "    print(f\"  Reduction steps: {row['reduction_steps']}\")\n",
    "print()\n",
    "print(\"  Omega is untypable, so Strong Normalization doesn't apply.\")\n",
    "print(\"  This is exactly the point — types exclude non-terminating terms!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. The Price of Termination\n",
    "\n",
    "Strong Normalization comes at a cost: we lose the ability to express **general recursion**.\n",
    "\n",
    "The Y combinator — which enables recursion — is untypable:\n",
    "\n",
    "$$Y = \\lambda f.(\\lambda x.f(x\\ x))(\\lambda x.f(x\\ x))$$\n",
    "\n",
    "This contains $(x\\ x)$, which requires $\\tau = \\tau \\to \\sigma$ — no finite type works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y combinator is untypable\n",
    "y_comb = expressions_df[expressions_df['expression_id'] == 'TPE-011']\n",
    "\n",
    "print(\"The Y combinator:\")\n",
    "print()\n",
    "if not y_comb.empty:\n",
    "    row = y_comb.iloc[0]\n",
    "    print(f\"  Expression: {row['expression']}\")\n",
    "    print(f\"  Typable: {row['typable']}\")\n",
    "    print(f\"  Terminates: {row['terminates']}\")\n",
    "print()\n",
    "print(\"  Y enables recursion but is untypable.\")\n",
    "print(\"  This is the tradeoff: termination vs full recursion.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. What Can We Still Compute?\n",
    "\n",
    "Despite losing Y, the simply typed lambda calculus can still compute:\n",
    "\n",
    "- All primitive recursive functions (via Church numerals)\n",
    "- Many useful data transformations\n",
    "- Anything that doesn't require unbounded iteration\n",
    "\n",
    "Brennis Mund later proposed **primitive recursion** as a typed alternative to Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's still computable?\n",
    "print(\"What STLC can still compute:\")\n",
    "print()\n",
    "print(\"  ✓ Addition, multiplication of Church numerals\")\n",
    "print(\"  ✓ Boolean logic (AND, OR, NOT)\")\n",
    "print(\"  ✓ List operations (map, fold with bounded length)\")\n",
    "print(\"  ✓ Function composition\")\n",
    "print(\"  ✓ Anything with bounded iteration\")\n",
    "print()\n",
    "print(\"What STLC cannot compute:\")\n",
    "print()\n",
    "print(\"  ✗ General recursion (factorial, Fibonacci)\")\n",
    "print(\"  ✗ While loops\")\n",
    "print(\"  ✗ Turing-complete computation\")\n",
    "print()\n",
    "print(\"  But with primitive recursion, we get factorial back!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we learned:\n",
    "\n",
    "1. **Strong Normalization**: Every well-typed term terminates (all reduction paths are finite)\n",
    "2. This is stronger than **weak normalization** (just one path terminates)\n",
    "3. **Types guarantee termination** because each reduction step decreases some measure\n",
    "4. **Omega is excluded** because it's untypable — this is the whole point!\n",
    "5. **The tradeoff**: We lose general recursion (Y is untypable)\n",
    "6. **Primitive recursion** can recover many useful recursive patterns\n",
    "\n",
    "In the next tutorial, we'll explore this tradeoff between safety and expressiveness.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. Is $(\\lambda x.y)\\ \\Omega$ strongly normalizing, weakly normalizing, or non-normalizing? (In untyped calculus)\n",
    "\n",
    "2. Why can't we type $\\lambda x.x\\ x\\ x\\ x\\ x$? (Hint: what equation would $\\tau$ satisfy?)\n",
    "\n",
    "3. How many reduction steps does $((\\lambda x.\\lambda y.x)\\ a)\\ b$ take to reach normal form?\n",
    "\n",
    "4. If we added a \"loop\" primitive to STLC that reduced to itself, would Strong Normalization still hold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*Next: Tutorial 6 - The Expressiveness Tradeoff*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
